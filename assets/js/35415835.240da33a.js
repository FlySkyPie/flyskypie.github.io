"use strict";(self.webpackChunkflyskypie_github_io=self.webpackChunkflyskypie_github_io||[]).push([[33392],{8220:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>h,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>u});var n=s(11527),i=s(88717);const o={slug:"2026-01-15_llm-observability",authors:["weiji"],tags:["LLM Observability"]},a="LLM \u53ef\u89c0\u6e2c\u7b46\u8a18",r={permalink:"/posts/2026-01-15_llm-observability",source:"@site/post/2026-01-15_llm-observability/index.md",title:"LLM \u53ef\u89c0\u6e2c\u7b46\u8a18",description:"\u4eca\u5929\u89c0\u5bdf\u5230\u4e00\u500b\u6709\u8da3\u7684\u73fe\u8c61\uff0c\u7d00\u9304\u4e00\u4e0b\u3002",date:"2026-01-15T00:00:00.000Z",formattedDate:"January 15, 2026",tags:[{label:"LLM Observability",permalink:"/posts/tags/llm-observability"}],hasTruncateMarker:!1,authors:[{name:"Wei Ji",title:"\u9583\u4eae\u75c7\u5019\u7fa4\u5de5\u7a0b\u5c4d",url:"https://github.com/FlySkyPie",imageURL:"https://avatars.githubusercontent.com/u/9475660",key:"weiji"}],frontMatter:{slug:"2026-01-15_llm-observability",authors:["weiji"],tags:["LLM Observability"]},unlisted:!1,nextItem:{title:"\u81ea\u67b6\u641c\u5c0b\u5f15\u64ce\u5957\u9910 (YaCy + SearXNG + Local Deep Research)",permalink:"/posts/2026-01-12_search-engine"}},h={authorsImageUrls:[void 0]},u=[];function l(e){const t={blockquote:"blockquote",code:"code",p:"p",pre:"pre",...(0,i.a)(),...e.components},{Head:s}=t;return s||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s,{children:(0,n.jsx)("meta",{property:"og:image",content:"https://raw.githubusercontent.com/FlySkyPie/flyskypie.github.io/main/post/2026-01-15_llm-observability/00_cover.webp"})}),"\n",(0,n.jsx)(t.p,{children:"\u4eca\u5929\u89c0\u5bdf\u5230\u4e00\u500b\u6709\u8da3\u7684\u73fe\u8c61\uff0c\u7d00\u9304\u4e00\u4e0b\u3002"}),"\n",(0,n.jsx)(t.p,{children:"\u539f\u59cb\u8acb\u6c42\uff1a"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:" You will have follow up questions. First, identify if your knowledge is outdated (high chance). Today: 2026-01-15. Generate 3 high-quality internet search questions to exactly answer: Which text structure is better for LLM prompts?\n- Markdown based\n- XML based\nConsider the case with a task have multiple output, output blocks with XML tags seems is more reliable approach?\n\nLanguage Rules:\nProcess the task in English (sort questions, search with English, search ranking...). \nOnly final response (the task is doing Summary) with Chinese (zh_TW).\n\n\nFormat: One question per line, e.g. \n Q: question1 \n Q: question2\n"})}),"\n",(0,n.jsx)(t.p,{children:"LLM \u7684\u56de\u7b54\uff1a"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"\u4ee5\u4e0b\u662f\u4e09\u500b\u9ad8\u54c1\u8cea\u7684\u641c\u5c0b\u554f\u984c\uff0c\u9069\u7528\u65bc\u67e5\u8a62 Markdown \u8207 XML \u5728 LLM \u63d0\u793a\u8a9e\u4e2d\u7684\u53ef\u9760\u6027\u6bd4\u8f03\uff1a\n\nQ: Is XML-based prompt structure more reliable than Markdown for multi-output LLM tasks?  \nQ: What are the advantages and disadvantages of Markdown-based vs XML-based prompt structures for large language models?  \nQ: Does XML-based output formatting improve consistency and parsing reliability compared to Markdown in LLM prompts?\n"})}),"\n",(0,n.jsx)(t.p,{children:"\u4e0d\u904e OpenAI API \u5176\u5be6\u4e5f\u6703\u900f\u9732\u63a8\u7406\u904e\u7a0b\uff08Reasoning\uff09\uff1a"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:'We need to respond: "You will have follow up questions. First, identify if your knowledge is outdated (high chance). Today: 2026-01-15. Generate 3 high-quality internet search questions to exactly answer: Which text structure is better for LLM prompts? - Markdown based - XML based Consider the case with a task have multiple output, output blocks with XML tags seems is more reliable approach? Language Rules: Process the task in English (sort questions, search with English, search ranking...). Only final response (the task is doing Summary) with Chinese (zh_TW). Format: One question per line, e.g. Q: question1 Q: question2"\n\nWe need to produce 3 search questions. They must be high-quality, for search queries. Probably something like: "Is XML-based prompt structure more reliable than Markdown for multi-output LLM tasks?" etc.\n\nWe need to output only the final response with Chinese (zh_TW). That means the final output should be Chinese? But the questions themselves are in English. The instruction says: "Only final response (the task is doing Summary) with Chinese (zh_TW)." Wait. The user wants 3 high-quality internet search questions to exactly answer the query. But then the system says only final response with Chinese. That seems contradictory. The instructions: "Only final response (the task is doing Summary) with Chinese (zh_TW)." So the final response should be in Chinese. But the format: "One question per line, e.g. Q: question1 Q: question2". That format presumably remains. But the content is in English? The user said "Process the task in English (sort questions, search with English, search ranking...). Only final response (the task is doing Summary) with Chinese (zh_TW)."\n\nSo we need to produce the final response in Chinese. But the questions themselves? The example shows "Q: question1" etc, presumably in English. But the final response should be in Chinese. Maybe we can write the questions in Chinese? But the instruction says "Process the task in English". That might refer to sorting, search queries, etc. But the final output should be Chinese. So maybe we produce the questions in Chinese? Or we produce them in English but the final response is Chinese? The example is in English.\n\nWe should interpret: The actual content (questions) should be in English because we want to search. But the final response (the entire output) should be in Chinese. So we can say:\n\nQ: Is using XML tags for multi-output LLM prompts more reliable than using Markdown formatting? \nQ: What are the advantages and disadvantages of Markdown-based vs XML-based prompt structures for large language models? \nQ: In LLM prompt design, does XML-based output formatting improve consistency and parsing reliability compared to Markdown?\n\nBut we must output this in Chinese. Maybe we can translate the entire set into Chinese? But then the search queries would be in Chinese, which might not be as effective for search. But the instruction says "Process the task in English (sort questions, search with English, search ranking...). Only final response (the task is doing Summary) with Chinese (zh_TW)." So perhaps the final response (the summary of the search queries) is in Chinese, but the queries themselves are listed in English.\n\nThus we produce:\n\nQ: Is XML-based prompt structure more reliable than Markdown for multi-output LLM tasks?\n\nBut maybe we need to phrase them as search queries. So maybe like:\n\nQ: "XML vs Markdown prompt structure reliability for multiple outputs in LLM"\n\nQ: "Advantages of XML tags in LLM prompt design over Markdown formatting"\n\nQ: "How does XML-based output block improve consistency and parsing for LLM prompts compared to Markdown"\n\nBut we need to produce exactly 3 high-quality internet search questions. We\'ll produce them as:\n\nQ: "Is XML-based prompt structure more reliable than Markdown for multi-output LLM tasks?"\nQ: "What are the advantages and disadvantages of Markdown-based vs XML-based prompt structures for large language models?"\nQ: "Does XML-based output formatting improve consistency and parsing reliability compared to Markdown in LLM prompts?"\n\nThen we output in Chinese: "\u4ee5\u4e0b\u662f\u4e09\u500b\u9ad8\u54c1\u8cea\u7684\u641c\u5c0b\u554f\u984c..." But we need to follow the format: one question per line, prefixed with Q:. That format likely stays in English. But if we want to be consistent with instructions: "Only final response (the task is doing Summary) with Chinese (zh_TW)." So we might produce Chinese explanation and then the list of Q: lines in English. But the output must be Chinese. So maybe we can put the questions in Chinese too. But then they\'d not be English search queries. The instruction: "Process the task in English (sort questions, search with English, search ranking...). Only final response (the task is doing Summary) with Chinese (zh_TW)." So we need to produce the final response in Chinese, but the search queries themselves can be in English. But we need to output them as part of the final response. The final response should be in Chinese, but we can include English lines. It\'s ambiguous.\n\nBetter to produce Chinese text explaining that these are the search queries, then list them in English. That keeps final response Chinese. So:\n\n\u4ee5\u4e0b\u662f\u4e09\u500b\u9ad8\u54c1\u8cea\u7684\u641c\u5c0b\u554f\u984c\uff0c\u9069\u7528\u65bc\u67e5\u8a62 Markdown \u8207 XML \u5728 LLM \u63d0\u793a\u8a9e\u4e2d\u7684\u53ef\u9760\u6027\u6bd4\u8f03\uff1a\n\nQ: Is XML-based prompt structure more reliable than Markdown for multi-output LLM tasks?\nQ: What are the advantages and disadvantages of Markdown-based vs XML-based prompt structures for large language models?\nQ: Does XML-based output formatting improve consistency and parsing reliability compared to Markdown in LLM prompts?\n\nWe can do that. That satisfies the instructions.\n'})}),"\n",(0,n.jsxs)(t.blockquote,{children:["\n",(0,n.jsx)(t.p,{children:"But then the system says only final response with Chinese. That seems contradictory."}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"\u6307\u51fa\u7576\u4e0b\u7684\u63d0\u793a\u8a5e\u5c0d LLM \u4f86\u8aaa\u53ef\u80fd\u4e0d\u5920\u76f4\u89c0\uff0cReasoning \u7684\u5167\u5bb9\u5728\u4e00\u822c\u7684 LLM \u61c9\u7528\u7a0b\u5f0f\u57fa\u672c\u4e0a\u662f\u4e0d\u53ef\u898b\u7684\uff0c\u4f46\u662f\u5b83\u4f3c\u4e4e\u662f\u8abf\u8a66\u63d0\u793a\u8a5e\u7684\u91cd\u8981\u5de5\u5177\u3002"})]})}function p(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},88717:(e,t,s)=>{s.d(t,{Z:()=>r,a:()=>a});var n=s(50959);const i={},o=n.createContext(i);function a(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),n.createElement(o.Provider,{value:t},e.children)}}}]);